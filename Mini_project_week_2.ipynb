{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c8fdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0930hrs', '1524hrs', 'Not stated', '0730hrs', '1300hrs',\n",
       "       '1055 hrs', '1630hrs', '1130hrs', 'PM', '1150hrs', '1500hrs',\n",
       "       '1600', '1615 hrs', '1210hrs', '1200hrs', '1211 hrs', '1400hrs',\n",
       "       '1100hrs', 'pm', '0945hrs', '1430hrs', '1210 hrs', '1340hrs',\n",
       "       'Unknown', '0815hrs', '1503hrs', '1830hrs', '1645 hrs', '1711hrs',\n",
       "       '1600hrs', '1330hrs', '1615hr', '1710hr', '?', '1637hr', 'AM',\n",
       "       '1600hr', '1735hrs', '1115hrs', '1118hrs', '1615hrs', '1100hr',\n",
       "       'after 1200hr', '1400hr', 15.5, '13h15', '9h', 1300, '14h',\n",
       "       '15h30', '13h30', '9h15', 'Not advised', '13h40', '12h30', '16h00',\n",
       "       nan, '11h30', '06h30', '20h00', '13h00', '11h12', '16h30', '15h00',\n",
       "       '02h00', '09h15', 'Early Morning', '16h32', '11h00', 'Morning',\n",
       "       '10h30', '13h20', '14h00', '09h00', '10h20', '15h05', '17h00',\n",
       "       '15h45', '07h45', '10h40', '07h50', '01h00', '10h00', 'Afternoon',\n",
       "       '19h30', 'Evening', '17h50', '09h30', '08h45', '\"Midday\"', '16h25',\n",
       "       '13h55', '13h50', '17h20', '13h45', '10h10', '14h35', 'Night',\n",
       "       '1500h ', '19h15', '11h20', '07h15', '07h00', '18h00', '08h00',\n",
       "       '14h20', '17h30', '07h20', '14h50', '-16h30', '12h00', '17h17',\n",
       "       '11h15', '19h00', '07h53', '16h10', '11h17', '17h45', '10jh45',\n",
       "       'Early  morning', '13h12', '07h30', '11hoo', '11h43', '10h15',\n",
       "       '14h09', '12h15', '19h12', '15h20', '16h40', '11h24', '12h50',\n",
       "       '07h31', '14h45', '1040hrs', '19h20', 'Dusk', '11h45', '06h40',\n",
       "       '`17h00', '07h51', '11h46', '20h30', '12h23', '07h07', '16h39',\n",
       "       '15h57', '14h30', '16h45', '10j30', '08h15', '08h56', '15h40',\n",
       "       '18h30', '07h58', '17h40', '09h00-10h00', '17h10', '09h36',\n",
       "       '08h40', '06h00', 'Sunset', '10h45', 1415, '14h00-15h00', '14h15',\n",
       "       '09h08', '15h59', '08h30', '12h20', '10h50', 'Midday', '09h40',\n",
       "       '14h33', '12h58', '\"Evening\"', '16h15', '23h00', '06h50', '12h45',\n",
       "       '11h55', '22h20', '08h48', '16h21', '16h26', '18h45', '03h00',\n",
       "       '06h15', 'Before 10h00', '06h45', 'Early afternoon', '06h55',\n",
       "       '13h42', '09h29', '10h47', '14h11', '15h35', '14h40',\n",
       "       '14h00  -15h00', 'Late afternoon', '16h50', '21h50', '17h35',\n",
       "       '19h00, Dusk', '15h01', 1000, '23h30', '10h44', '13h19',\n",
       "       'Shortly before 12h00', '17h34', '08h50', '09h50', '9h00', '10h43',\n",
       "       'After noon', '15h15', '19h05', '14h30 / 15h30', '22h00', '16h20',\n",
       "       '14h34', '15h25', '14h55', '17h46', 'Morning ', '15h49',\n",
       "       'Midnight', '09h30 / 10h00', '18h15', '04h00', '10h25',\n",
       "       '10h45-11h15', '15h52', '19h45', '12h10', '18h05', '11h41',\n",
       "       '12h25', '17h51', '16h12', '09h45', '05h00', '03h30',\n",
       "       'Sometime between 06h00 & 08hoo', '16h18', '11h10',\n",
       "       '07h00 - 08h00', '18h15-18h30', '17h01', '09h57', '08h20', '17h58',\n",
       "       '15h19', '10h55', '15h55', '12h40', '16h05', '14h10', '13h24',\n",
       "       '09h00 - 09h30', '0830', '11h40', '08h10', '15h56',\n",
       "       'Just before noon', '07h56', '16h35', '09h05', '19h28', '12h38',\n",
       "       '05h50', '15h50', '11h05', 'Early morning', 'Dawn', '05h45',\n",
       "       '13h25', '13h26', '09h11', '18h20', '13h51', 'A.M.', '08h05',\n",
       "       '10h35', '15h44', '21h00', 'Lunchtime', '15j45', '09h35', '10h27',\n",
       "       '10h16', '0500', 'Before 07h00', '09h20', '10h00 -- 11h00',\n",
       "       '12h05', '14h21', '18h50', '15h53', '\"Just before 11h00\"',\n",
       "       '11h115', '20h15', '12h39', '07h05', '  ', '13h05', 'N', '11h50',\n",
       "       'Just before sundown', '17h55', '22h30', '17h15', '11h30 ',\n",
       "       '06h10', 'Between 05h00 and 08h00', '07h08', '17h00 or 17h40',\n",
       "       '>08h00', '--', '12h02', '12h55', '16h14', '17h11', '00h30',\n",
       "       '14h37', '10h07', '13h53', '13h23', 'Just after 12h00', '02h30',\n",
       "       '11h56', ' ', 'Shortly after midnight', '14h25', '13h345', '\\xa0 ',\n",
       "       '06h47', '09h00 -10h00', '20h45 (Sunset)', 'Late morning', 'P.M.',\n",
       "       '18h40', '13h14', '13h06', 'Shortly before 13h00', '12h34',\n",
       "       '11h53', '8:04 pm', '12h46', '12h48', '17h42', '12h35',\n",
       "       'Possibly same incident as 2000.08.21', 'After Dusk', '11h57',\n",
       "       'Noon', '11h25', '18h25', '10h28', '14h16', '09h55',\n",
       "       '2 hours after Opperman', '09h30 ', 'Mid afternoon', 'Mid morning',\n",
       "       '11h48', '11h00 / 11h30', '07h19', '13h37', '11h06', '\"Night\"',\n",
       "       '18h30?', '11h58', '11h51', '18h12', '07h10', '07h40', '12h33',\n",
       "       '30 minutes after 1992.07.08.a', '>06h45', '15h06', '12h54',\n",
       "       'Between 06h00 & 07h20', '16h55', '05h40', '<07h30', '21h30',\n",
       "       '17h00 Sunset', 'Nightfall', 'X', '08h57', '18h30 (Sunset)',\n",
       "       '06j00', '08h35', '10h22', '02h45', 'Prior to 10h37', 'Daybreak',\n",
       "       '18h10', '>12h00', 'Mid-morning', '08h55', '16h30 or 18h00',\n",
       "       'Just before dawn', ' 14h00', 'Daytime', 'Dark', '10h00 / 11h00',\n",
       "       '\"After lunch\"', '07h32', '15h00 or 15h45', '>17h00',\n",
       "       '19h00 / 20h00', '12h45 / 13h45', '14h00 - 15h00', 'night',\n",
       "       '03h45 - 04h00', '13h10', '09h30 / 15h30', '08h00 / 09h30',\n",
       "       '19h35', '12h00 to 14h00', '13h35', 'Late night', '01h32',\n",
       "       '10h30 or 13h30', '16h23', '15h00j', 'Midday.', '\"After dark\"',\n",
       "       '10h00 or 14h00', '19h10', '2 hrs before sunset', '18h15 to 21h30',\n",
       "       1500, '\"shortly before dusk\"', '>17h30', '>14h30',\n",
       "       'Between 11h00 & 12h00', 'After 04h00',\n",
       "       '11h01 -time of ship sinking', 'Ship aban-doned at 03h10', '19h55',\n",
       "       'After dusk',\n",
       "       'FATAL  (Wire netting installed at local beaches after this incident.)',\n",
       "       '01h30', 'After midnight', 'Late afternon', '05h30', '08h58',\n",
       "       '\"Early evening\"', 'Late Afternoon', '   ', 'Before daybreak',\n",
       "       'dusk', 'Before 10h30', '06h00 -- 07h00', '01h50', '17h00-18h00',\n",
       "       '19h00-20h00'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_excel(\"/Users/snow/Documents/IRON HACK COURSE/Week 2/Mini Project/Week-2-Mini-Project---Shark-Attacks/GSAF5.xls\")\n",
    "df[\"Time\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a0a2b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7045, 23) \n",
      "\n",
      "Date              6089\n",
      "Year               261\n",
      "Type                13\n",
      "Country            247\n",
      "State              937\n",
      "Location          4595\n",
      "Activity          1606\n",
      "Name              5770\n",
      "Sex                 10\n",
      "Age                250\n",
      "Injury            4162\n",
      "Fatal Y/N           12\n",
      "Time               460\n",
      "Species           1724\n",
      "Source            5384\n",
      "pdf               6789\n",
      "href formula      6784\n",
      "href              6776\n",
      "Case Number       6777\n",
      "Case Number.1     6775\n",
      "original order    6797\n",
      "Unnamed: 21          1\n",
      "Unnamed: 22          2\n",
      "dtype: int64 \n",
      "\n",
      "type\n",
      "Unprovoked             5032\n",
      "Under investigation     834\n",
      "Provoked                582\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "sex\n",
      "M    5645\n",
      "F     803\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "['M' 'F'] \n",
      "\n",
      "time_clean\n",
      "NaN          3128\n",
      "Afternoon    2105\n",
      "Morning       766\n",
      "Evening       394\n",
      "Dawn           55\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>location</th>\n",
       "      <th>activity</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>injury</th>\n",
       "      <th>fatal_y/n</th>\n",
       "      <th>time_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6th September</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Long Reef Sydney</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>M</td>\n",
       "      <td>57</td>\n",
       "      <td>Both legs and arm severed</td>\n",
       "      <td>Y</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st September</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Horseshoe reef Key Largo</td>\n",
       "      <td>Snorkeling</td>\n",
       "      <td>M</td>\n",
       "      <td>8</td>\n",
       "      <td>Bite to leg</td>\n",
       "      <td>N</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Galveston</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>Bite to leg</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Cabarita Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>None sustained board severly damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Atlantic Ocean near Big Grand Cay</td>\n",
       "      <td>North of Grand Bahama near Freeport</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>Severe injuries no detail</td>\n",
       "      <td>N</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date    year        type    country  \\\n",
       "0  6th September  2025.0  Unprovoked  Australia   \n",
       "1  1st September  2025.0  Unprovoked        USA   \n",
       "2    30th August  2025.0  Unprovoked        USA   \n",
       "3    18th August  2025.0  Unprovoked  Australia   \n",
       "4    17th August  2025.0  Unprovoked    Bahamas   \n",
       "\n",
       "                               state                             location  \\\n",
       "0                                NSW                     Long Reef Sydney   \n",
       "1                            Florida             Horseshoe reef Key Largo   \n",
       "2                              Texas                            Galveston   \n",
       "3                                NSW                       Cabarita Beach   \n",
       "4  Atlantic Ocean near Big Grand Cay  North of Grand Bahama near Freeport   \n",
       "\n",
       "       activity sex age                                injury fatal_y/n  \\\n",
       "0       Surfing   M  57             Both legs and arm severed         Y   \n",
       "1    Snorkeling   M   8                           Bite to leg         N   \n",
       "2      Swimming   F   8                           Bite to leg         N   \n",
       "3       Surfing   M   ?  None sustained board severly damaged         N   \n",
       "4  Spearfishing   M  63             Severe injuries no detail         N   \n",
       "\n",
       "  time_clean  \n",
       "0    Morning  \n",
       "1  Afternoon  \n",
       "2        NaN  \n",
       "3    Morning  \n",
       "4  Afternoon  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install xlrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df = pd.read_excel(\"/Users/snow/Documents/IRON HACK COURSE/Week 2/Mini Project/Week-2-Mini-Project---Shark-Attacks/GSAF5.xls\")\n",
    "\n",
    "# Now we want to clean the dataframe a bit\n",
    "# First lets have a look at the Dataframe\n",
    "print(df.shape, '\\n')\n",
    "print(df.nunique(), '\\n')\n",
    "\n",
    "# Then we want to standardize the column names\n",
    "df.columns = df.columns.str.lower().str.replace(\" \",\"_\").str.replace(\":\", \"\")\n",
    "df.rename(columns={\"species_\":\"species\"}, inplace=True)\n",
    "\n",
    "# We can see that there are some weird values in the 'Type' column such as 'Boat', 'Questionable ', 'Unconfirmed'\n",
    "# We want to merge these values into a single category called 'Under investigation'\n",
    "\n",
    "# First, we drop the rows where 'Type' and 'Sex' are null\n",
    "df.dropna(subset=[\"sex\", \"type\"], inplace=True)\n",
    "\n",
    "# Then, we replace the values in the 'Type' column\n",
    "def replace_type(value):\n",
    "    if isinstance(value, str):\n",
    "        # Remove white spaces and compare lower-case\n",
    "        value_clean = value.strip().lower()\n",
    "        valid_types = ['unprovoked', 'provoked']\n",
    "        if value_clean not in valid_types:\n",
    "            return \"Under investigation\"\n",
    "        else:\n",
    "            # Return the standardized value (capitalize first letter)\n",
    "            return value_clean.capitalize()\n",
    "    return value\n",
    "\n",
    "df[\"type\"] = df[\"type\"].apply(replace_type)\n",
    "\n",
    "# Now we can check the value counts again\n",
    "print(df[\"type\"].value_counts(), '\\n')\n",
    "\n",
    "# Now we want to clean the 'sex' column in the same way\n",
    "def replace_sex(value):\n",
    "    if isinstance(value, str):\n",
    "        if value[0].lower() == \"f\":\n",
    "            return \"F\"\n",
    "        else:\n",
    "            return \"M\"\n",
    "\n",
    "df[\"sex\"] = df[\"sex\"].apply(replace_sex)\n",
    "print(df[\"sex\"].value_counts(), '\\n')\n",
    "print(df['sex'].unique(), '\\n')\n",
    "\n",
    "# Now lets dive into the 'time' column and clean it\n",
    "# We want to have four unique values with the following criteria:\n",
    "# 6 am until noon -> Morning\n",
    "# Noon until 6 pm -> Afternoon\n",
    "# 6 pm until midnight -> Night\n",
    "# Midnight until 6 am -> Dawn\n",
    "\n",
    "df['time'].unique()\n",
    "#df['time'].value_counts()\n",
    "\n",
    "# We need to use regex to extract the hour and minutes from the 'time' column\n",
    "# We will create a function to clean the 'time' column\n",
    "def time_cleaner(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan # Return NaN for null values\n",
    "    \n",
    "    val = str(val).strip().lower() # Convert to string and lower case\n",
    "    \n",
    "    # Remove unwanted characters\n",
    "    val = re.sub(r'[^0-9a-z: ]', '', val) # Keep only alphanumeric characters, colon, and space\n",
    "\n",
    "    # The previous regex cleans the column to keep only the essential characters needed for time parsing\n",
    "    # The ^ inside []indicates negation, means \"match everything EXCEPT these characters\", so we basically removing unwanted punctuation, uppercase letters, and special characters while preserving the useful parts\n",
    "\n",
    "    # Simple textual cases using any() for efficiency\n",
    "    if any(word in val for word in ['dawn', 'daybreak', 'sunrise', 'early morning']):\n",
    "        return 'Dawn'\n",
    "    if any(word in val for word in ['morning']):\n",
    "        return 'Morning'\n",
    "    if any(word in val for word in ['noon', 'midday', 'afternoon', 'after noon', 'mid afternoon', 'late afternoon']):\n",
    "        return 'Afternoon'\n",
    "    if any(word in val for word in ['evening', 'dusk', 'sunset', 'night', 'dark']):\n",
    "        return 'Evening'\n",
    "\n",
    "    # Numeric time formats using regex to capture hour and optional minutes with or without separators\n",
    "    # This regex is designed to extract time information from various formats\n",
    "    match = re.search(r'(\\d{1,2})[:h]?(\\d{0,2})?', val)\n",
    "    if match:\n",
    "        hour = int(match.group(1)) # Extract hour from regex group 1\n",
    "        minutes = match.group(2) if match.group(2) else '00' # Extract minutes from regex group 2 if available\n",
    "\n",
    "        # 4 digits format without separator (ex: 1530)\n",
    "        if len(val) >= 4 and val[:4].isdigit(): # Check if first 4 characters are digits\n",
    "            hour = int(val[:2]) # First two digits are hour\n",
    "            minutes = val[2:4] # Last two digits are minutes\n",
    "\n",
    "        # Adjust hour if minutes are superior to 45\n",
    "        if minutes and minutes.isdigit() and int(minutes) > 45: # If minutes are greater than 45, round up the hour\n",
    "            hour += 1\n",
    "        hour = hour % 24  # Ensure hour is within 0-23\n",
    "\n",
    "        # Convert in 4 periods of the day\n",
    "        if 5 <= hour < 11:\n",
    "            return 'Morning'\n",
    "        elif 11 <= hour < 18:\n",
    "            return 'Afternoon'\n",
    "        elif 18 <= hour < 23:\n",
    "            return 'Evening'\n",
    "        else:\n",
    "            return 'Dawn'\n",
    "\n",
    "    # If nothing matches, return NaN\n",
    "    return np.nan\n",
    "\n",
    "# We apply the function to the 'time' column\n",
    "df['time_clean'] = df['time'].apply(time_cleaner)\n",
    "\n",
    "# To check the result\n",
    "print(df['time_clean'].value_counts(dropna=False))\n",
    "\n",
    "# # Now we want to drop the columns that are not useful for our analysis\n",
    "df = df.drop(df.columns[[7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]], axis=1, inplace=False)\n",
    "# # We are droping time column because we created a new column 'time_clean' with the cleaned values\n",
    "# # We did drop the name column because of the data privacy policy in some countries\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b9b512e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time_clean\n",
       "count        3320\n",
       "unique          4\n",
       "top     Afternoon\n",
       "freq         1581"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()\n",
    "df[['time_clean']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b52af60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Unprovoked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              type\n",
       "count         6448\n",
       "unique           3\n",
       "top     Unprovoked\n",
       "freq          5032"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[['type']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d7cb3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sex\n",
       "count   6448\n",
       "unique     2\n",
       "top        M\n",
       "freq    5645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df[['sex']].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
